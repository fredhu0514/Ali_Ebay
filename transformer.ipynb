{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_raw = pd.read_excel('./shopify reviews.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(399, 10)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_raw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>app_id</th>\n",
       "      <th>author</th>\n",
       "      <th>rating</th>\n",
       "      <th>posted_at</th>\n",
       "      <th>body</th>\n",
       "      <th>helpful_count</th>\n",
       "      <th>helpful_count.1</th>\n",
       "      <th>developer_reply_posted_at</th>\n",
       "      <th>label</th>\n",
       "      <th>1  安全性（用户信息安全）</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b1da53a4-0474-4700-9620-bf386bc033fb</td>\n",
       "      <td>Consuela</td>\n",
       "      <td>5</td>\n",
       "      <td>2020-08-06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>6</td>\n",
       "      <td>2  易用性（UI设计美观合理便捷）</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b1da53a4-0474-4700-9620-bf386bc033fb</td>\n",
       "      <td>L'Atelier Global</td>\n",
       "      <td>5</td>\n",
       "      <td>2020-08-04</td>\n",
       "      <td>Still setting up my store, and after initially...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>6</td>\n",
       "      <td>3  效率（服务器、多终端）</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b1da53a4-0474-4700-9620-bf386bc033fb</td>\n",
       "      <td>city'super E-Shop</td>\n",
       "      <td>5</td>\n",
       "      <td>2020-08-04</td>\n",
       "      <td>This is an excellent search app, which they ha...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>7</td>\n",
       "      <td>4  兼容性（多地区、多语言兼容；与其他平台互通）</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b1da53a4-0474-4700-9620-bf386bc033fb</td>\n",
       "      <td>PortableHandwashing.com</td>\n",
       "      <td>5</td>\n",
       "      <td>2020-07-30</td>\n",
       "      <td>A+, great great great customer service! thanks...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>7</td>\n",
       "      <td>5  应用程序基本功能（搜索功能、制作尺码表、聊天功能、即时品牌页面、程序运行快、删减产品、...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b1da53a4-0474-4700-9620-bf386bc033fb</td>\n",
       "      <td>ICCTUNING</td>\n",
       "      <td>5</td>\n",
       "      <td>2020-07-28</td>\n",
       "      <td>I'm begginig to use this app, the search engin...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2</td>\n",
       "      <td>6  定制化功能</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 app_id                   author  rating  \\\n",
       "0  b1da53a4-0474-4700-9620-bf386bc033fb                 Consuela       5   \n",
       "1  b1da53a4-0474-4700-9620-bf386bc033fb         L'Atelier Global       5   \n",
       "2  b1da53a4-0474-4700-9620-bf386bc033fb        city'super E-Shop       5   \n",
       "3  b1da53a4-0474-4700-9620-bf386bc033fb  PortableHandwashing.com       5   \n",
       "4  b1da53a4-0474-4700-9620-bf386bc033fb                ICCTUNING       5   \n",
       "\n",
       "   posted_at                                               body  \\\n",
       "0 2020-08-06                                                NaN   \n",
       "1 2020-08-04  Still setting up my store, and after initially...   \n",
       "2 2020-08-04  This is an excellent search app, which they ha...   \n",
       "3 2020-07-30  A+, great great great customer service! thanks...   \n",
       "4 2020-07-28  I'm begginig to use this app, the search engin...   \n",
       "\n",
       "   helpful_count helpful_count.1 developer_reply_posted_at  label  \\\n",
       "0              0             NaN                       NaT      6   \n",
       "1              0             NaN                       NaT      6   \n",
       "2              0             NaN                       NaT      7   \n",
       "3              0             NaN                       NaT      7   \n",
       "4              0             NaN                       NaT      2   \n",
       "\n",
       "                                      1  安全性（用户信息安全）  \n",
       "0                                 2  易用性（UI设计美观合理便捷）  \n",
       "1                                     3  效率（服务器、多终端）  \n",
       "2                          4  兼容性（多地区、多语言兼容；与其他平台互通）  \n",
       "3  5  应用程序基本功能（搜索功能、制作尺码表、聊天功能、即时品牌页面、程序运行快、删减产品、...  \n",
       "4                                           6  定制化功能  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data2 = data_raw[['body', 'label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(399, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Still setting up my store, and after initially...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This is an excellent search app, which they ha...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A+, great great great customer service! thanks...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I'm begginig to use this app, the search engin...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                body  label\n",
       "0                                                NaN      6\n",
       "1  Still setting up my store, and after initially...      6\n",
       "2  This is an excellent search app, which they ha...      7\n",
       "3  A+, great great great customer service! thanks...      7\n",
       "4  I'm begginig to use this app, the search engin...      2"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data2 = data2.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(398, 2)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Still setting up my store, and after initially...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This is an excellent search app, which they ha...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A+, great great great customer service! thanks...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I'm begginig to use this app, the search engin...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Great work guys. Easy app to install and use. ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                body  label\n",
       "1  Still setting up my store, and after initially...      6\n",
       "2  This is an excellent search app, which they ha...      7\n",
       "3  A+, great great great customer service! thanks...      7\n",
       "4  I'm begginig to use this app, the search engin...      2\n",
       "5  Great work guys. Easy app to install and use. ...      5"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data = data2.copy()\n",
    "data[\"body\"] = data[\"body\"].apply(lambda s : s.replace(\"\\n\", ' ').replace('\\r', ' ').replace(\"\\t\", \" \"))\n",
    "data.to_csv('train.tsv', sep = \"\\t\", columns=['label', 'body'], index=0, header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Still setting up my store, and after initially...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This is an excellent search app, which they ha...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A+, great great great customer service! thanks...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I'm begginig to use this app, the search engin...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Great work guys. Easy app to install and use. ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                body  label\n",
       "1  Still setting up my store, and after initially...      6\n",
       "2  This is an excellent search app, which they ha...      7\n",
       "3  A+, great great great customer service! thanks...      7\n",
       "4  I'm begginig to use this app, the search engin...      2\n",
       "5  Great work guys. Easy app to install and use. ...      5"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = data.loc[0:50]\n",
    "test_data.to_csv('test.tsv', sep = \"\\t\", columns=['label', 'body'], index=0, header=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## build dataset\n",
    "### first step: define tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Still',\n",
       " 'setting',\n",
       " 'up',\n",
       " 'my',\n",
       " 'store',\n",
       " ',',\n",
       " 'and',\n",
       " 'after',\n",
       " 'initially',\n",
       " 'paying',\n",
       " 'for',\n",
       " 'another',\n",
       " 'search',\n",
       " 'app',\n",
       " ',',\n",
       " 'I',\n",
       " 'made',\n",
       " 'the',\n",
       " 'decision',\n",
       " 'to',\n",
       " 'try',\n",
       " 'Instant',\n",
       " 'Search',\n",
       " '.',\n",
       " 'Their',\n",
       " 'aesthetic',\n",
       " 'really',\n",
       " 'suits',\n",
       " 'my',\n",
       " 'type',\n",
       " 'of',\n",
       " 'store',\n",
       " ',',\n",
       " 'and',\n",
       " 'the',\n",
       " 'custom',\n",
       " 'settings',\n",
       " 'pr',\n",
       " '.',\n",
       " '.',\n",
       " '.']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split all the sentences into words\n",
    "def my_tokenizer(s):\n",
    "    s = s.replace(',', \" ,\").replace(\".\", \" .\").replace(\"?\", \" ?\").replace(\"!\", \" !\")\n",
    "    return s.split()\n",
    "\n",
    "my_tokenizer('Still setting up my store, and after initially paying for another search app, I made the decision to try Instant Search.   Their aesthetic really suits my type of store, and the custom settings pr...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### second step: define string clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# No abbreviations\n",
    "def clean_str(string):\n",
    "    string = re.sub(\"[^A-Za-z0-9\\-\\?\\!\\.\\,]\", \" \", string).lower()\n",
    "    string = string.replace(\"that's\", \"that is\")\n",
    "    string = string.replace(\"isn't\", \"is not\")\n",
    "    string = string.replace(\"don't\", \"do not\")\n",
    "    string = string.replace(\"didn't\", \"did not\")\n",
    "    string = string.replace(\"won't\", \"will not\")\n",
    "    string = string.replace(\"can't\", \"can not\")\n",
    "    string = string.replace(\"you're\", \"you are\")\n",
    "    string = string.replace(\"they're\", \"they are\")\n",
    "    string = string.replace(\"you'll\", \"you will\")\n",
    "    string = string.replace(\"we'll\", \"we will\")\n",
    "    string = string.replace(\"what's\", \"what is\")\n",
    "    string = string.replace(\"i'm\", \"i am\")\n",
    "    string = string.replace(\"let's\", \"let us\")\n",
    "    return string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### third step: build vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from torchtext.vocab import vocab\n",
    "\n",
    "def build_vocab(tokenizer, filepath, min_freq, specials=None):\n",
    "    if specials is None:\n",
    "        # UNK means unknown word, a word that doesn't exist the the vocabulary set\n",
    "        # <PAD>, <EOS> and <GO> are all represented as <PAD> token. To complement the matrix given to be trained.\n",
    "        specials = ['<unk>', '<pad>']\n",
    "    counter = Counter()\n",
    "    with open(filepath, encoding='utf8') as f:\n",
    "        for string_ in f:\n",
    "            string_ = string_.strip().split('\\t')[-1][:-1] # strip removes spaces at the start and the end\n",
    "            counter.update(tokenizer(clean_str(string_)))\n",
    "    # torchtext.vocab.vocab(ordered_dict: Dict, min_freq: int = 1, specials: Optional[List[str]] = None, special_first: bool = True) \n",
    "        # ordered_dict – Ordered Dictionary mapping tokens to their corresponding occurance frequencies.\n",
    "        # min_freq – The minimum frequency needed to include a token in the vocabulary.\n",
    "        # specials – Special symbols to add. The order of supplied tokens will be preserved.\n",
    "        # special_first – Indicates whether to insert symbols at the beginning or at the end.\n",
    "    return vocab(counter, min_freq=min_freq, specials=specials)\n",
    "\n",
    "test_vocab = build_vocab(my_tokenizer, 'train.tsv', 1, ['<unk>', '<pad>'])\n",
    "# index – Value of default index. This index will be returned when OOV token is queried. (OOV is out of vocabulary)\n",
    "test_vocab.set_default_index(0)\n",
    "test_vocab['gsdfg'] # so is 0 returned because of `test_vocab.set_default_index(0)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def pad_sequence(sequences, batch_first=False, max_len=None, padding_value=0):\n",
    "    max_size = sequences[0].size()\n",
    "    trailing_dims = max_size[1:]\n",
    "    length = max_len\n",
    "    max_len = max([s.size(0) for s in sequences])\n",
    "    if length is not None:\n",
    "        max_len = max(length, max_len)\n",
    "    if batch_first:\n",
    "        out_dims = (len(sequences), max_len) + trailing_dims\n",
    "    else:\n",
    "        out_dims = (max_len, len(sequences)) + trailing_dims\n",
    "    out_tensor = sequences[0].data.new(*out_dims).fill_(padding_value)\n",
    "    for i, tensor in enumerate(sequences):\n",
    "        length = tensor.size(0)\n",
    "        # use index notation to prevent duplicate references to the tensor\n",
    "        if batch_first:\n",
    "            out_tensor[i, :length, ...] = tensor\n",
    "        else:\n",
    "            out_tensor[:length, i, ...] = tensor\n",
    "    return out_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### fourth step: trans Token sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 8, 38, 35, 42, 16, 43, 41, 15, 23])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = ' and am so happy I found this app.'\n",
    "s = clean_str(s)\n",
    "tmp_vocab = build_vocab(my_tokenizer, filepath='./train.tsv', min_freq=1)\n",
    "torch.tensor([tmp_vocab[token] for token in my_tokenizer(s)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "797"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "class LoadSentenceClassificationDataset():\n",
    "    def __init__(self, train_file_path=None,  # 训练集路径\n",
    "                 tokenizer=None,\n",
    "                 batch_size=2,\n",
    "                 min_freq=1,  # 最小词频，去掉小于min_freq的词\n",
    "                 max_sen_len='same'):  # 最大句子长度，默认设置其长度为整个数据集中最长样本的长度\n",
    "        # max_sen_len = None时，表示按每个batch中最长的样本长度进行padding\n",
    "        # 根据训练预料建立字典\n",
    "        self.tokenizer = tokenizer\n",
    "        self.min_freq = min_freq\n",
    "        self.specials = ['<unk>', '<pad>']\n",
    "        self.vocab = build_vocab(self.tokenizer,filepath=train_file_path,\n",
    "                                 min_freq=self.min_freq,specials=self.specials)\n",
    "        self.vocab.set_default_index(0) # minimum is 1 so 0 is fine, otherwise use -1 as recommended\n",
    "        self.PAD_IDX = self.vocab['<pad>']\n",
    "        self.UNK_IDX = self.vocab['<unk>']\n",
    "        self.batch_size = batch_size\n",
    "        self.max_sen_len = max_sen_len\n",
    "\n",
    "    def data_process(self, filepath):\n",
    "        \"\"\"\n",
    "        将每一句话中的每一个词根据字典转换成索引的形式，同时返回所有样本中最长样本的长度\n",
    "        :param filepath: 数据集路径\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        raw_iter = iter(open(filepath, encoding=\"utf8\"))\n",
    "        data = []\n",
    "        max_len = 0\n",
    "        for raw in raw_iter:\n",
    "            # BEFORE::: line = raw.rstrip(\"\\n\").split(\",\") ::: And it was csv!!!\n",
    "            line = raw.rstrip(\"\\n\").split(\"\\t\")\n",
    "            s, l = line[-1][:-1], line[0] # ⚠️ weird because this line truncated the string with comma, sometimes no label\n",
    "            s = clean_str(s)\n",
    "            tensor_ = torch.tensor([self.vocab[token] for token in\n",
    "                                    self.tokenizer(s)], dtype=torch.long)\n",
    "            l = torch.tensor(int(l) - 1, dtype=torch.long) # ⚠️ possible error\n",
    "            max_len = max(max_len, tensor_.size(0)) # find the longest sentence\n",
    "            data.append((tensor_, l)) # ⚠️ possible error\n",
    "        return data, max_len\n",
    "\n",
    "    def generate_batch(self, data_batch):\n",
    "        batch_sentence, batch_label = [], []\n",
    "        for (sen, label) in data_batch:  # 开始对一个batch中的每一个样本进行处理。\n",
    "            batch_sentence.append(sen)\n",
    "            batch_label.append(label)\n",
    "        batch_sentence = pad_sequence(batch_sentence,  # [batch_size,max_len]\n",
    "                                      padding_value=self.PAD_IDX,\n",
    "                                      batch_first=False,\n",
    "                                      max_len=self.max_sen_len)\n",
    "        batch_label = torch.tensor(batch_label, dtype=torch.long)\n",
    "        return batch_sentence, batch_label\n",
    "\n",
    "    def load_train_val_test_data(self, train_file_paths, test_file_paths):\n",
    "        train_data, max_sen_len = self.data_process(train_file_paths)  # 得到处理好的所有样本\n",
    "        if self.max_sen_len == 'same':\n",
    "            self.max_sen_len = max_sen_len\n",
    "        test_data, _ = self.data_process(test_file_paths)\n",
    "        train_iter = DataLoader(train_data, batch_size=self.batch_size,  # 构造DataLoader\n",
    "                                shuffle=True, collate_fn=self.generate_batch) # complete the max length with padding\n",
    "        test_iter = DataLoader(test_data, batch_size=self.batch_size,\n",
    "                               shuffle=True, collate_fn=self.generate_batch)\n",
    "        return train_iter, test_iter\n",
    "\n",
    "dataset = LoadSentenceClassificationDataset('train.tsv', my_tokenizer)\n",
    "tensor_data, max_len = dataset.data_process('train.tsv')\n",
    "max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([33, 2])\n",
      "torch.Size([246, 2])\n",
      "torch.Size([49, 2])\n",
      "torch.Size([28, 2])\n",
      "torch.Size([118, 2])\n",
      "torch.Size([67, 2])\n",
      "torch.Size([58, 2])\n",
      "torch.Size([25, 2])\n",
      "torch.Size([81, 2])\n",
      "torch.Size([30, 2])\n",
      "torch.Size([49, 2])\n",
      "torch.Size([62, 2])\n",
      "torch.Size([55, 2])\n",
      "torch.Size([180, 2])\n",
      "torch.Size([120, 2])\n",
      "torch.Size([76, 2])\n",
      "torch.Size([40, 2])\n",
      "torch.Size([94, 2])\n",
      "torch.Size([67, 2])\n",
      "torch.Size([69, 2])\n",
      "torch.Size([19, 2])\n",
      "torch.Size([49, 2])\n",
      "torch.Size([30, 2])\n",
      "torch.Size([50, 2])\n",
      "torch.Size([82, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([37, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([60, 2])\n",
      "torch.Size([41, 2])\n",
      "torch.Size([29, 2])\n",
      "torch.Size([95, 2])\n",
      "torch.Size([25, 2])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([86, 2])\n",
      "torch.Size([125, 2])\n",
      "torch.Size([95, 2])\n",
      "torch.Size([44, 2])\n",
      "torch.Size([45, 2])\n",
      "torch.Size([67, 2])\n",
      "torch.Size([51, 2])\n",
      "torch.Size([94, 2])\n",
      "torch.Size([29, 2])\n",
      "torch.Size([61, 2])\n",
      "torch.Size([60, 2])\n",
      "torch.Size([141, 2])\n",
      "torch.Size([165, 2])\n",
      "torch.Size([78, 2])\n",
      "torch.Size([111, 2])\n",
      "torch.Size([30, 2])\n",
      "torch.Size([37, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([54, 2])\n",
      "torch.Size([122, 2])\n",
      "torch.Size([23, 2])\n",
      "torch.Size([79, 2])\n",
      "torch.Size([65, 2])\n",
      "torch.Size([127, 2])\n",
      "torch.Size([24, 2])\n",
      "torch.Size([57, 2])\n",
      "torch.Size([199, 2])\n",
      "torch.Size([54, 2])\n",
      "torch.Size([50, 2])\n",
      "torch.Size([72, 2])\n",
      "torch.Size([75, 2])\n",
      "torch.Size([34, 2])\n",
      "torch.Size([27, 2])\n",
      "torch.Size([212, 2])\n",
      "torch.Size([34, 2])\n",
      "torch.Size([64, 2])\n",
      "torch.Size([62, 2])\n",
      "torch.Size([73, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([25, 2])\n",
      "torch.Size([30, 2])\n",
      "torch.Size([67, 2])\n",
      "torch.Size([23, 2])\n",
      "torch.Size([85, 2])\n",
      "torch.Size([29, 2])\n",
      "torch.Size([25, 2])\n",
      "torch.Size([43, 2])\n",
      "torch.Size([35, 2])\n",
      "torch.Size([198, 2])\n",
      "torch.Size([50, 2])\n",
      "torch.Size([127, 2])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([66, 2])\n",
      "torch.Size([52, 2])\n",
      "torch.Size([71, 2])\n",
      "torch.Size([88, 2])\n",
      "torch.Size([116, 2])\n",
      "torch.Size([27, 2])\n",
      "torch.Size([93, 2])\n",
      "torch.Size([56, 2])\n",
      "torch.Size([78, 2])\n",
      "torch.Size([76, 2])\n",
      "torch.Size([85, 2])\n",
      "torch.Size([39, 2])\n",
      "torch.Size([97, 2])\n",
      "torch.Size([42, 2])\n",
      "torch.Size([42, 2])\n",
      "torch.Size([32, 2])\n",
      "torch.Size([113, 2])\n",
      "torch.Size([67, 2])\n",
      "torch.Size([47, 2])\n",
      "torch.Size([72, 2])\n",
      "torch.Size([63, 2])\n",
      "torch.Size([25, 2])\n",
      "torch.Size([50, 2])\n",
      "torch.Size([35, 2])\n",
      "torch.Size([33, 2])\n",
      "torch.Size([24, 2])\n",
      "torch.Size([64, 2])\n",
      "torch.Size([117, 2])\n",
      "torch.Size([93, 2])\n",
      "torch.Size([48, 2])\n",
      "torch.Size([324, 2])\n",
      "torch.Size([30, 2])\n",
      "torch.Size([53, 2])\n",
      "torch.Size([39, 2])\n",
      "torch.Size([215, 2])\n",
      "torch.Size([33, 2])\n",
      "torch.Size([22, 2])\n",
      "torch.Size([21, 2])\n",
      "torch.Size([54, 2])\n",
      "torch.Size([43, 2])\n",
      "torch.Size([79, 2])\n",
      "torch.Size([77, 2])\n",
      "torch.Size([30, 2])\n",
      "torch.Size([33, 2])\n",
      "torch.Size([78, 2])\n",
      "torch.Size([76, 2])\n",
      "torch.Size([85, 2])\n",
      "torch.Size([37, 2])\n",
      "torch.Size([103, 2])\n",
      "torch.Size([72, 2])\n",
      "torch.Size([64, 2])\n",
      "torch.Size([56, 2])\n",
      "torch.Size([45, 2])\n",
      "torch.Size([52, 2])\n",
      "torch.Size([33, 2])\n",
      "torch.Size([62, 2])\n",
      "torch.Size([80, 2])\n",
      "torch.Size([46, 2])\n",
      "torch.Size([141, 2])\n",
      "torch.Size([95, 2])\n",
      "torch.Size([156, 2])\n",
      "torch.Size([36, 2])\n",
      "torch.Size([29, 2])\n",
      "torch.Size([38, 2])\n",
      "torch.Size([532, 2])\n",
      "torch.Size([37, 2])\n",
      "torch.Size([27, 2])\n",
      "torch.Size([40, 2])\n",
      "torch.Size([101, 2])\n",
      "torch.Size([46, 2])\n",
      "torch.Size([44, 2])\n",
      "torch.Size([41, 2])\n",
      "torch.Size([23, 2])\n",
      "torch.Size([28, 2])\n",
      "torch.Size([39, 2])\n",
      "torch.Size([147, 2])\n",
      "torch.Size([26, 2])\n",
      "torch.Size([43, 2])\n",
      "torch.Size([40, 2])\n",
      "torch.Size([25, 2])\n",
      "torch.Size([52, 2])\n",
      "torch.Size([66, 2])\n",
      "torch.Size([33, 2])\n",
      "torch.Size([53, 2])\n",
      "torch.Size([78, 2])\n",
      "torch.Size([65, 2])\n",
      "torch.Size([64, 2])\n",
      "torch.Size([797, 2])\n",
      "torch.Size([28, 2])\n",
      "torch.Size([53, 2])\n",
      "torch.Size([177, 2])\n",
      "torch.Size([77, 2])\n",
      "torch.Size([42, 2])\n",
      "torch.Size([46, 2])\n",
      "torch.Size([29, 2])\n",
      "torch.Size([67, 2])\n",
      "torch.Size([42, 2])\n",
      "torch.Size([60, 2])\n",
      "torch.Size([131, 2])\n",
      "torch.Size([92, 2])\n",
      "torch.Size([53, 2])\n",
      "torch.Size([38, 2])\n",
      "torch.Size([48, 2])\n",
      "torch.Size([54, 2])\n",
      "torch.Size([69, 2])\n",
      "torch.Size([30, 2])\n",
      "torch.Size([126, 2])\n",
      "torch.Size([67, 2])\n",
      "torch.Size([51, 2])\n",
      "torch.Size([98, 2])\n",
      "torch.Size([41, 2])\n",
      "torch.Size([75, 2])\n",
      "torch.Size([71, 2])\n"
     ]
    }
   ],
   "source": [
    "path = \"train.tsv\"\n",
    "data_loader = LoadSentenceClassificationDataset(train_file_path=path,\n",
    "                                                    tokenizer=my_tokenizer,\n",
    "                                                    max_sen_len=None)\n",
    "# max_sen_len = None时，表示按每个batch中最长的样本长度进行padding\n",
    "# Feature is always 2, label and body\n",
    "data, max_len = data_loader.data_process(path)\n",
    "train_iter, test_iter = data_loader.load_train_val_test_data(path, path)\n",
    "for sample, label in train_iter:\n",
    "    print(sample.shape)  # [seq_len,batch_size]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## network structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from torch.nn.init import xavier_uniform_\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Parameter\n",
    "import torch.nn as nn\n",
    "import copy\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_print_shape = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_head_attention_forward(query,  # [tgt_len,batch_size, embed_dim]\n",
    "                                 key,  # [src_len, batch_size, embed_dim]\n",
    "                                 value,  # [src_len, batch_size, embed_dim]\n",
    "                                 num_heads,\n",
    "                                 dropout_p,\n",
    "                                 out_proj,  # [embed_dim = vdim * num_heads, embed_dim = vdim * num_heads]\n",
    "                                 training=True,\n",
    "                                 key_padding_mask=None,  # [batch_size,src_len/tgt_len]\n",
    "                                 q_proj=None,  # [embed_dim,kdim * num_heads]\n",
    "                                 k_proj=None,  # [embed_dim, kdim * num_heads]\n",
    "                                 v_proj=None,  # [embed_dim, vdim * num_heads]\n",
    "                                 attn_mask=None,  # [tgt_len,src_len] or [num_heads*batch_size,tgt_len, src_len]\n",
    "                                 ):\n",
    "    q = q_proj(query)\n",
    "    #  [tgt_len,batch_size, embed_dim] x [embed_dim,kdim * num_heads] = [tgt_len,batch_size,kdim * num_heads]\n",
    "\n",
    "    k = k_proj(key)\n",
    "    # [src_len, batch_size, embed_dim] x [embed_dim, kdim * num_heads] = [src_len, batch_size, kdim * num_heads]\n",
    "\n",
    "    v = v_proj(value)\n",
    "    # [src_len, batch_size, embed_dim] x [embed_dim, vdim * num_heads] = [src_len, batch_size, vdim * num_heads]\n",
    "    if is_print_shape:\n",
    "        print(\"\" + \"=\" * 80)\n",
    "        print(\"进入多头注意力计算:\")\n",
    "        print(\n",
    "            f\"\\t 多头num_heads = {num_heads}, d_model={query.size(-1)}, d_k = d_v = d_model/num_heads={query.size(-1) // num_heads}\")\n",
    "        print(f\"\\t query的shape([tgt_len, batch_size, embed_dim]):{query.shape}\")\n",
    "        print(f\"\\t  W_q 的shape([embed_dim,kdim * num_heads]):{q_proj.weight.shape}\")\n",
    "        print(f\"\\t   Q  的shape([tgt_len, batch_size,kdim * num_heads]):{q.shape}\")\n",
    "        print(\"\\t\" + \"-\" * 70)\n",
    "\n",
    "        print(f\"\\t  key 的shape([src_len,batch_size, embed_dim]):{key.shape}\")\n",
    "        print(f\"\\t  W_k 的shape([embed_dim,kdim * num_heads]):{k_proj.weight.shape}\")\n",
    "        print(f\"\\t   K  的shape([src_len,batch_size,kdim * num_heads]):{k.shape}\")\n",
    "        print(\"\\t\" + \"-\" * 70)\n",
    "\n",
    "        print(f\"\\t value的shape([src_len,batch_size, embed_dim]):{value.shape}\")\n",
    "        print(f\"\\t  W_v 的shape([embed_dim,vdim * num_heads]):{v_proj.weight.shape}\")\n",
    "        print(f\"\\t   V  的shape([src_len,batch_size,vdim * num_heads]):{v.shape}\")\n",
    "        print(\"\\t\" + \"-\" * 70)\n",
    "        print(\"\\t ***** 注意，这里的W_q, W_k, W_v是多个head同时进行计算的. 因此，Q,K,V分别也是包含了多个head的q,k,v堆叠起来的结果 *****\")\n",
    "\n",
    "    tgt_len, bsz, embed_dim = query.size()  # [tgt_len,batch_size, embed_dim]\n",
    "    src_len = key.size(0)\n",
    "    head_dim = embed_dim // num_heads  # num_heads * head_dim = embed_dim\n",
    "    scaling = float(head_dim) ** -0.5\n",
    "    q = q * scaling  # [query_len,batch_size,kdim * num_heads]\n",
    "\n",
    "    if attn_mask is not None:  # [tgt_len,src_len] or [num_heads*batch_size,tgt_len, src_len]\n",
    "        if attn_mask.dim() == 2:\n",
    "            attn_mask = attn_mask.unsqueeze(0)  # [1, tgt_len,src_len]\n",
    "            if list(attn_mask.size()) != [1, query.size(0), key.size(0)]:\n",
    "                raise RuntimeError('The size of the 2D attn_mask is not correct.')\n",
    "        elif attn_mask.dim() == 3:\n",
    "            if list(attn_mask.size()) != [bsz * num_heads, query.size(0), key.size(0)]:\n",
    "                raise RuntimeError('The size of the 3D attn_mask is not correct.')\n",
    "        # 现在 atten_mask 的维度就变成了3D\n",
    "\n",
    "    q = q.contiguous().view(tgt_len, bsz * num_heads, head_dim).transpose(0, 1)\n",
    "    # [batch_size * num_heads,tgt_len,kdim]\n",
    "    # 因为前面是num_heads个头一起参与的计算，所以这里要进行一下变形，以便于后面计算。 且同时交换了0，1两个维度\n",
    "    k = k.contiguous().view(-1, bsz * num_heads, head_dim).transpose(0, 1)  # [batch_size * num_heads,src_len,kdim]\n",
    "    v = v.contiguous().view(-1, bsz * num_heads, head_dim).transpose(0, 1)  # [batch_size * num_heads,src_len,vdim]\n",
    "    attn_output_weights = torch.bmm(q, k.transpose(1, 2))\n",
    "    # [batch_size * num_heads,tgt_len,kdim] x [batch_size * num_heads, kdim, src_len]\n",
    "    # =  [batch_size * num_heads, tgt_len, src_len]  这就num_heads个QK相乘后的注意力矩阵\n",
    "\n",
    "    if attn_mask is not None:\n",
    "        attn_output_weights += attn_mask  # [batch_size * num_heads, tgt_len, src_len]\n",
    "\n",
    "    if key_padding_mask is not None:\n",
    "        attn_output_weights = attn_output_weights.view(bsz, num_heads, tgt_len, src_len)\n",
    "        # 变成 [batch_size, num_heads, tgt_len, src_len]的形状\n",
    "        attn_output_weights = attn_output_weights.masked_fill(\n",
    "            key_padding_mask.unsqueeze(1).unsqueeze(2),  # 扩展维度，从[batch_size,src_len]变成[batch_size,1,1,src_len]\n",
    "            float('-inf'))  #\n",
    "        attn_output_weights = attn_output_weights.view(bsz * num_heads, tgt_len,\n",
    "                                                       src_len)  # [batch_size * num_heads, tgt_len, src_len]\n",
    "\n",
    "    attn_output_weights = F.softmax(attn_output_weights, dim=-1)  # [batch_size * num_heads, tgt_len, src_len]\n",
    "    attn_output_weights = F.dropout(attn_output_weights, p=dropout_p, training=training)\n",
    "    attn_output = torch.bmm(attn_output_weights, v)\n",
    "    # Z = [batch_size * num_heads, tgt_len, src_len]  x  [batch_size * num_heads,src_len,vdim]\n",
    "    # = # [batch_size * num_heads,tgt_len,vdim]\n",
    "    # 这就num_heads个Attention(Q,K,V)结果\n",
    "\n",
    "    attn_output = attn_output.transpose(0, 1).contiguous().view(tgt_len, bsz, embed_dim)\n",
    "    # 先transpose成 [tgt_len, batch_size* num_heads ,kdim]\n",
    "    # 再view成 [tgt_len,batch_size,num_heads*kdim]\n",
    "    attn_output_weights = attn_output_weights.view(bsz, num_heads, tgt_len, src_len)\n",
    "\n",
    "    Z = out_proj(attn_output)\n",
    "    # 这里就是多个z  线性组合成Z  [tgt_len,batch_size,embed_dim]\n",
    "    if is_print_shape:\n",
    "        print(f\"\\t 多头注意力中,多头计算结束后的形状（堆叠）为([tgt_len,batch_size,num_heads*kdim]){attn_output.shape}\")\n",
    "        print(f\"\\t 多头计算结束后，再进行线性变换时的权重W_o的形状为([num_heads*vdim, num_heads*vdim  ]){out_proj.weight.shape}\")\n",
    "        print(f\"\\t 多头线性变化后的形状为([tgt_len,batch_size,embed_dim]) {Z.shape}\")\n",
    "    return Z, attn_output_weights.sum(dim=1) / num_heads  # average attention weights over heads\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class MyMultiheadAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    多头注意力机制的计算公式为（就是论文第5页的公式）：\n",
    "    .. math::\n",
    "        \\text{MultiHead}(Q, K, V) = \\text{Concat}(head_1,\\dots,head_h)W^O\n",
    "        \\text{where} head_i = \\text{Attention}(QW_i^Q, KW_i^K, VW_i^V)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, embed_dim, num_heads, dropout=0., bias=True):\n",
    "        super(MyMultiheadAttention, self).__init__()\n",
    "        \"\"\"\n",
    "        :param embed_dim:   词嵌入的维度，也就是前面的d_model参数，论文中的默认值为512\n",
    "        :param num_heads:   多头注意力机制中多头的数量，也就是前面的nhead参数， 论文默认值为 8 // FREDHU heads => think of CNN filters\n",
    "        :param dropout:\n",
    "        :param bias:        最后对多头的注意力（组合）输出进行线性变换时，是否使用偏置\n",
    "        \"\"\"\n",
    "        self.embed_dim = embed_dim  # 前面的d_model参数\n",
    "        self.head_dim = embed_dim // num_heads  # head_dim 指的就是d_k,d_v\n",
    "        self.kdim = self.head_dim\n",
    "        self.vdim = self.head_dim\n",
    "\n",
    "        self.num_heads = num_heads  # 多头个数\n",
    "        self.dropout = dropout # FREDHU in case overfit\n",
    "\n",
    "        assert self.head_dim * num_heads == self.embed_dim, \"embed_dim 除以 num_heads必须为整数\"\n",
    "        # 上面的限制条件就是论文中的  d_k = d_v = d_model/n_head 条件\n",
    "\n",
    "        self.q_proj = nn.Linear(embed_dim, embed_dim, bias=bias)  # embed_dim = kdim * num_heads\n",
    "        # 这里第二个维度之所以是embed_dim，实际上这里是同时初始化了num_heads个W_q堆叠起来的, 也就是num_heads个头\n",
    "        self.k_proj = nn.Linear(embed_dim, embed_dim, bias=bias)  # W_k,  embed_dim = kdim * num_heads\n",
    "        self.v_proj = nn.Linear(embed_dim, embed_dim, bias=bias)  # W_v,  embed_dim = vdim * num_heads\n",
    "        self.out_proj = nn.Linear(embed_dim, embed_dim, bias=bias)\n",
    "        # 最后将所有的Z组合起来的时候，也是一次性完成， embed_dim = vdim * num_heads\n",
    "        self._reset_parameters()\n",
    "\n",
    "    def _reset_parameters(self):\n",
    "        \"\"\"\n",
    "        以特定方式来初始化参数\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        for p in self.parameters():\n",
    "            if p.dim() > 1:\n",
    "                xavier_uniform_(p)\n",
    "\n",
    "    def forward(self, query, key, value, attn_mask=None, key_padding_mask=None):\n",
    "        \"\"\"\n",
    "        在论文中，编码时query, key, value 都是同一个输入， 解码时 输入的部分也都是同一个输入，\n",
    "        解码和编码交互时 key,value指的是 memory, query指的是tgt\n",
    "        :param query: # [tgt_len, batch_size, embed_dim], tgt_len 表示目标序列的长度\n",
    "        :param key:  #  [src_len, batch_size, embed_dim], src_len 表示源序列的长度\n",
    "        :param value: # [src_len, batch_size, embed_dim], src_len 表示源序列的长度\n",
    "        :param attn_mask: # [tgt_len,src_len] or [num_heads*batch_size,tgt_len, src_len]\n",
    "                一般只在解码时使用，为了并行一次喂入所有解码部分的输入，所以要用mask来进行掩盖当前时刻之后的位置信息\n",
    "        :param key_padding_mask: [batch_size, src_len], src_len 表示源序列的长度\n",
    "        :return:\n",
    "        attn_output: [tgt_len, batch_size, embed_dim]\n",
    "        attn_output_weights: # [batch_size, tgt_len, src_len]\n",
    "        \"\"\"\n",
    "        return multi_head_attention_forward(query, key, value, self.num_heads,\n",
    "                                            self.dropout,\n",
    "                                            out_proj=self.out_proj,\n",
    "                                            training=self.training,\n",
    "                                            key_padding_mask=key_padding_mask,\n",
    "                                            q_proj=self.q_proj,\n",
    "                                            k_proj=self.k_proj,\n",
    "                                            v_proj=self.v_proj,\n",
    "                                            attn_mask=attn_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyTransformerEncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, nhead, dim_feedforward=2048, dropout=0.1):\n",
    "        super(MyTransformerEncoderLayer, self).__init__()\n",
    "        \"\"\"\n",
    "        :param d_model:         d_k = d_v = d_model/nhead = 64, 模型中向量的维度，论文默认值为 512\n",
    "        :param nhead:           多头注意力机制中多头的数量，论文默认为值 8\n",
    "        :param dim_feedforward: 全连接中向量的维度，论文默认值为 2048\n",
    "        :param dropout:         丢弃率，论文中的默认值为 0.1\n",
    "        \"\"\"\n",
    "        self.self_attn = MyMultiheadAttention(d_model, nhead, dropout=dropout)\n",
    "\n",
    "        # Implementation of Feedforward model\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "\n",
    "        self.linear1 = nn.Linear(d_model, dim_feedforward)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear2 = nn.Linear(dim_feedforward, d_model)\n",
    "        self.activation = F.relu # torch funtions\n",
    "\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "\n",
    "    def forward(self, src, src_mask=None, src_key_padding_mask=None):\n",
    "        \"\"\"\n",
    "        :param src: 编码部分的输入，形状为 [src_len,batch_size, embed_dim]\n",
    "        :param src_mask:  编码部分输入的padding情况，形状为 [batch_size, src_len]\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        src2 = self.self_attn(src, src, src, attn_mask=src_mask,\n",
    "                              key_padding_mask=src_key_padding_mask, )[0]  # 计算多头注意力\n",
    "        # src2: [src_len,batch_size,num_heads*kdim] num_heads*kdim = embed_dim\n",
    "        src = src + self.dropout1(src2)  # 残差连接\n",
    "        src = self.norm1(src)  # [src_len,batch_size,num_heads*kdim]\n",
    "\n",
    "        src2 = self.activation(self.linear1(src))  # [src_len,batch_size,dim_feedforward]\n",
    "        src2 = self.linear2(self.dropout(src2))  # [src_len,batch_size,num_heads*kdim]\n",
    "        src = src + self.dropout2(src2)\n",
    "        src = self.norm2(src)\n",
    "        return src  # [src_len, batch_size, num_heads * kdim] <==> [src_len,batch_size,embed_dim]\n",
    "\n",
    "def _get_clones(module, N):\n",
    "    return nn.ModuleList([copy.deepcopy(module) for _ in range(N)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyTransformerEncoder(nn.Module):\n",
    "    def __init__(self, encoder_layer, num_layers, norm=None):\n",
    "        super(MyTransformerEncoder, self).__init__()\n",
    "        \"\"\"\n",
    "        encoder_layer: 就是包含有多头注意力机制的一个编码层\n",
    "        num_layers: 克隆得到多个encoder layers 论文中默认为6\n",
    "        norm: 归一化层\n",
    "        \"\"\"\n",
    "        self.layers = _get_clones(encoder_layer, num_layers)  # 克隆得到多个encoder layers 论文中默认为6\n",
    "        self.num_layers = num_layers\n",
    "        self.norm = norm\n",
    "\n",
    "    def forward(self, src, mask=None, src_key_padding_mask=None):\n",
    "        \"\"\"\n",
    "        :param src: 编码部分的输入，形状为 [src_len,batch_size, embed_dim]\n",
    "        :param mask:  编码部分输入的padding情况，形状为 [batch_size, src_len]\n",
    "        :return:# [src_len, batch_size, num_heads * kdim] <==> [src_len,batch_size,embed_dim]\n",
    "        \"\"\"\n",
    "        output = src\n",
    "        for mod in self.layers:\n",
    "            output = mod(output, src_mask=mask,\n",
    "                         src_key_padding_mask=src_key_padding_mask)  # 多个encoder layers层堆叠后的前向传播过程\n",
    "        if self.norm is not None:\n",
    "            output = self.norm(output) # FREDHU standarlize\n",
    "        return output  # [src_len, batch_size, num_heads * kdim] <==> [src_len,batch_size,embed_dim]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    r\"\"\"Inject some information about the relative or absolute position of the tokens\n",
    "        in the sequence. The positional encodings have the same dimension as\n",
    "        the embeddings, so that the two can be summed. Here, we use sine and cosine\n",
    "        functions of different frequencies.\n",
    "    .. math::\n",
    "        \\text{PosEncoder}(pos, 2i) = sin(pos/10000^(2i/d_model)) // FERDHU each i ocurs nhead times\n",
    "        \\text{PosEncoder}(pos, 2i+1) = cos(pos/10000^(2i/d_model))\n",
    "        \\text{where pos is the word position and i is the embed idx)\n",
    "    Args:\n",
    "        d_model: the embed dim (required).\n",
    "        dropout: the dropout value (default=0.1).\n",
    "        max_len: the max. length of the incoming sequence (default=5000).\n",
    "    Examples:\n",
    "        #>>> pos_encoder = PositionalEncoding(d_model)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        pe = torch.zeros(max_len, d_model)  # [max_len, d_model]\n",
    "        \"\"\"\n",
    "        \\text{PosEncoder}(pos, 2i) = sin(pos/10000^(2i/d_model)) // FERDHU each i ocurs nhead times\n",
    "        \\text{PosEncoder}(pos, 2i+1) = cos(pos/10000^(2i/d_model))\n",
    "        \"\"\"\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)  # [max_len, 1]\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))  # [d_model/2] ::: start=0, end, step=1\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)  # [max_len, d_model/2]\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)  # [max_len, 1, d_model]\n",
    "        # https://pytorch.org/docs/stable/_modules/torch/nn/modules/module.html#Module.register_buffer\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):  # [x_len, batch_size, d_model]\n",
    "        \"\"\"\n",
    "        :param x: [x_len, batch_size, emb_size]\n",
    "        :return: [x_len, batch_size, emb_size]\n",
    "        \"\"\"\n",
    "        x = x + self.pe[:x.size(0), :]  # [batch_size, max_len, d_model]\n",
    "        return self.dropout(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TokenEmbedding(nn.Module):\n",
    "    def __init__(self, vocab_size: int, emb_size):\n",
    "        super(TokenEmbedding, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, emb_size)\n",
    "        self.emb_size = emb_size\n",
    "\n",
    "    \"\"\"\n",
    "        :param tokens: shape : [len, batch_size]\n",
    "        :return: shape: [len, batch_size, emb_size]\n",
    "        \"\"\"\n",
    "\n",
    "    def forward(self, tokens): # ？？？？？\n",
    "        return self.embedding(tokens.long()) * math.sqrt(self.emb_size) # .long() == self.to(torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class ClassificationModel(nn.Module):\n",
    "    def __init__(self, vocab_size=None,\n",
    "                 d_model=512, nhead=8,\n",
    "                 num_encoder_layers=6,\n",
    "                 dim_feedforward=2048,\n",
    "                 dim_classification=64,\n",
    "                 num_classification=10,\n",
    "                 dropout=0.1):\n",
    "        super(ClassificationModel, self).__init__()\n",
    "        self.pos_embedding = PositionalEncoding(d_model=d_model, dropout=dropout)\n",
    "        self.src_token_embedding = TokenEmbedding(vocab_size, d_model)\n",
    "        encoder_layer = MyTransformerEncoderLayer(d_model, nhead,\n",
    "                                                  dim_feedforward,\n",
    "                                                  dropout)\n",
    "        encoder_norm = nn.LayerNorm(d_model)\n",
    "        self.encoder = MyTransformerEncoder(encoder_layer,\n",
    "                                            num_encoder_layers, encoder_norm)\n",
    "        self.classifier = nn.Sequential(nn.Linear(d_model, dim_classification),\n",
    "                                        nn.Dropout(dropout),\n",
    "                                        nn.Linear(dim_classification, num_classification))\n",
    "\n",
    "    def forward(self,\n",
    "                src,  # [src_len, batch_size]\n",
    "                src_mask=None,\n",
    "                src_key_padding_mask=None,  # [batsh_size, src_len]\n",
    "                concat_type='sum'  # 解码之后取所有位置相加，还是最后一个位置作为输出\n",
    "                ):\n",
    "        src_embed = self.src_token_embedding(src)  # [src_len, batch_size, embed_dim]\n",
    "        src_embed = self.pos_embedding(src_embed)  # [src_len, batch_size, embed_dim]\n",
    "        memory = self.encoder(src=src_embed,\n",
    "                              mask=src_mask,\n",
    "                              src_key_padding_mask=src_key_padding_mask)\n",
    "        # [src_len,batch_size,embed_dim]\n",
    "        if concat_type == 'sum':\n",
    "            memory = torch.sum(memory, dim=0)\n",
    "        elif concat_type == 'avg':\n",
    "            memory = torch.sum(memory, dim=0) / memory.size(0)\n",
    "        else:\n",
    "            memory = memory[-1, ::]  # 取最后一个时刻\n",
    "        # [src_len, batch_size, num_heads * kdim] <==> [src_len,batch_size,embed_dim]\n",
    "        out = self.classifier(memory)  # 输出logits\n",
    "        return out  # [batch_size, num_class]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 10])\n"
     ]
    }
   ],
   "source": [
    "src_len = 7\n",
    "batch_size = 2\n",
    "dmodel = 32\n",
    "num_head = 4\n",
    "src = torch.tensor([[4, 3, 2, 6, 0, 0, 0],\n",
    "                        [5, 7, 8, 2, 4, 0, 0]]).transpose(0, 1)  # 转换成 [src_len, batch_size]\n",
    "src_key_padding_mask = torch.tensor([[True, True, True, True, False, False, False],\n",
    "                                         [True, True, True, True, True, False, False]])\n",
    "model = ClassificationModel(vocab_size=10, d_model=dmodel, nhead=num_head)\n",
    "logits = model(src, src_key_padding_mask=src_key_padding_mask)\n",
    "print(logits.shape) # torch.Size([2, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.9460,  3.1425, -0.6631, -1.2480,  2.4230,  1.3177,  0.2487, -0.3032,\n",
       "         -1.1590,  0.6803],\n",
       "        [ 2.6779,  3.3154, -0.1594, -1.6539, -2.3415,  0.9372, -3.3019, -1.2542,\n",
       "          3.2723,  0.2104]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "\n",
    "class CustomSchedule(nn.Module):\n",
    "    def __init__(self, d_model, warmup_steps=4000):\n",
    "        super(CustomSchedule, self).__init__()\n",
    "        self.d_model = torch.tensor(d_model, dtype=torch.float32)\n",
    "        self.warmup_steps = warmup_steps\n",
    "        self.step = 1.\n",
    "\n",
    "    def __call__(self):\n",
    "        arg1 = self.step ** -0.5\n",
    "        arg2 = self.step * (self.warmup_steps ** -1.5)\n",
    "        self.step += 1.\n",
    "        return (self.d_model ** -0.5) * min(arg1, arg2)\n",
    "\n",
    "def train_model(config):\n",
    "    data_loader = LoadSentenceClassificationDataset(config.train_corpus_file_paths,\n",
    "                                                    my_tokenizer,\n",
    "                                                    batch_size=config.batch_size,\n",
    "                                                    min_freq=config.min_freq,\n",
    "                                                    max_sen_len=config.max_sen_len)\n",
    "    train_iter, test_iter = data_loader.load_train_val_test_data(\n",
    "        config.train_corpus_file_paths, config.test_corpus_file_paths)\n",
    "\n",
    "    classification_model = ClassificationModel(vocab_size=len(data_loader.vocab),\n",
    "                                               d_model=config.d_model,\n",
    "                                               nhead=config.num_head,\n",
    "                                               num_encoder_layers=config.num_encoder_layers,\n",
    "                                               dim_feedforward=config.dim_feedforward,\n",
    "                                               dim_classification=config.dim_classification,\n",
    "                                               num_classification=config.num_class,\n",
    "                                               dropout=config.dropout)\n",
    "\n",
    "    for p in classification_model.parameters():\n",
    "        if p.dim() > 1:\n",
    "            nn.init.xavier_uniform_(p)\n",
    "    model_save_path = os.path.join(config.model_save_dir, 'model.pt')\n",
    "    if os.path.exists(model_save_path):\n",
    "        loaded_paras = torch.load(model_save_path)\n",
    "        classification_model.load_state_dict(loaded_paras)\n",
    "        print(\"## 成功载入已有模型，进行追加训练......\")\n",
    "    classification_model = classification_model.to(config.device)\n",
    "    loss_fn = torch.nn.CrossEntropyLoss()\n",
    "    learning_rate = CustomSchedule(config.d_model) # FREDHU dynamic lr\n",
    "    optimizer = torch.optim.Adam(classification_model.parameters(),\n",
    "                                 lr=0.,\n",
    "                                 betas=(config.beta1, config.beta2),\n",
    "                                 eps=config.epsilon)\n",
    "    classification_model.train()\n",
    "    max_test_acc = 0\n",
    "    for epoch in range(config.epochs):\n",
    "        losses = 0\n",
    "        start_time = time.time()\n",
    "        for idx, (sample, label) in enumerate(train_iter):\n",
    "            sample = sample.to(config.device)  # [src_len, batch_size]\n",
    "            label = label.to(config.device)\n",
    "            padding_mask = (sample == data_loader.PAD_IDX).transpose(0, 1)\n",
    "            logits = classification_model(sample,\n",
    "                                          src_key_padding_mask=padding_mask)  # [batch_size,num_class]\n",
    "            optimizer.zero_grad()\n",
    "            loss = loss_fn(logits, label)\n",
    "            loss.backward()\n",
    "            lr = learning_rate()\n",
    "            for p in optimizer.param_groups:\n",
    "                p['lr'] = lr\n",
    "            optimizer.step()\n",
    "            losses += loss.item()\n",
    "\n",
    "            acc = (logits.argmax(1) == label).float().mean()\n",
    "            if idx % 10 == 0:\n",
    "                print(f\"Epoch: {epoch}, Batch[{idx}/{len(train_iter)}], \"\n",
    "                      f\"Train loss :{loss.item():.3f}, Train acc: {acc:.3f}\")\n",
    "        end_time = time.time()\n",
    "        train_loss = losses / len(train_iter)\n",
    "        print(f\"Epoch: {epoch}, Train loss: {train_loss:.3f}, Epoch time = {(end_time - start_time):.3f}s\")\n",
    "        if (epoch + 1) % config.model_save_per_epoch == 0:\n",
    "            acc = evaluate(test_iter, classification_model, config.device)\n",
    "            print(f\"Accuracy on test {acc:.3f}, max acc on test {max_test_acc:.3f}\")\n",
    "            if acc > max_test_acc:\n",
    "                max_test_acc = acc\n",
    "                torch.save(classification_model.state_dict(), model_save_path)\n",
    "\n",
    "def evaluate(data_iter, model, device):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        acc_sum, n = 0.0, 0\n",
    "        for x, y in data_iter:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            logits = model(x)\n",
    "            acc_sum += (logits.argmax(1) == y).float().sum().item()\n",
    "            n += len(y)\n",
    "        model.train()\n",
    "        return acc_sum / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "class Config():\n",
    "    \"\"\"\n",
    "    基于Transformer架构的类Translation模型配置类\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        #   数据集设置相关配置\n",
    "        self.project_dir = os.path.dirname(os.path.abspath('__file__'))\n",
    "        self.dataset_dir = os.path.join(self.project_dir, '.')\n",
    "        self.train_corpus_file_paths = os.path.join(self.dataset_dir, 'train.tsv')\n",
    "        # print(self.train_corpus_file_paths)\n",
    "        self.test_corpus_file_paths = os.path.join(self.dataset_dir, 'test.tsv')\n",
    "        self.min_freq = 1\n",
    "        self.max_sen_len = None\n",
    "\n",
    "        #  模型相关配置\n",
    "        self.batch_size = 128\n",
    "        self.d_model = 512\n",
    "        self.num_head = 8\n",
    "        self.num_encoder_layers = 6\n",
    "        self.num_decoder_layers = 6\n",
    "        self.dim_feedforward = 512\n",
    "        self.dim_classification = 256\n",
    "        self.num_class = 10\n",
    "        self.dropout = 0.1\n",
    "        self.concat_type = 'avg'\n",
    "        self.beta1 = 0.9\n",
    "        self.beta2 = 0.98\n",
    "        self.epsilon = 10e-9\n",
    "        self.device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "        self.epochs = 10\n",
    "        self.model_save_dir = os.path.join(self.project_dir, 'cache')\n",
    "        self.model_save_per_epoch = 2\n",
    "        if not os.path.exists(self.model_save_dir):\n",
    "            os.makedirs(self.model_save_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-70477d3da9de>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConfig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-46-f4ef25dc009d>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(config)\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m             \u001b[0mpadding_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mdata_loader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPAD_IDX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m             logits = classification_model(sample,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                           src_key_padding_mask=padding_mask)  # [batch_size,num_class]\n\u001b[1;32m     61\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-42-98f44fededbc>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src, src_mask, src_key_padding_mask, concat_type)\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0msrc_embed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc_token_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# [src_len, batch_size, embed_dim]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0msrc_embed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_embed\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# [src_len, batch_size, embed_dim]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         memory = self.encoder(src=src_embed,\n\u001b[0m\u001b[1;32m     31\u001b[0m                               \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msrc_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m                               src_key_padding_mask=src_key_padding_mask)\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-39-fd33088a50d1>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src, mask, src_key_padding_mask)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmod\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m             output = mod(output, src_mask=mask,\n\u001b[0m\u001b[1;32m     22\u001b[0m                          src_key_padding_mask=src_key_padding_mask)  # 多个encoder layers层堆叠后的前向传播过程\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-38-9bff79aaa69c>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src, src_mask, src_key_padding_mask)\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0;32mreturn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \"\"\"\n\u001b[0;32m---> 30\u001b[0;31m         src2 = self.self_attn(src, src, src, attn_mask=src_mask,\n\u001b[0m\u001b[1;32m     31\u001b[0m                               key_padding_mask=src_key_padding_mask, )[0]  # 计算多头注意力\n\u001b[1;32m     32\u001b[0m         \u001b[0;31m# src2: [src_len,batch_size,num_heads*kdim] num_heads*kdim = embed_dim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-37-9ae2b1324653>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, query, key, value, attn_mask, key_padding_mask)\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0mattn_output_weights\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# [batch_size, tgt_len, src_len]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \"\"\"\n\u001b[0;32m---> 59\u001b[0;31m         return multi_head_attention_forward(query, key, value, self.num_heads,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m                                             \u001b[0mout_proj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout_proj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-36-c080d94d42e3>\u001b[0m in \u001b[0;36mmulti_head_attention_forward\u001b[0;34m(query, key, value, num_heads, dropout_p, out_proj, training, key_padding_mask, q_proj, k_proj, v_proj, attn_mask)\u001b[0m\n\u001b[1;32m     78\u001b[0m                                                        src_len)  # [batch_size * num_heads, tgt_len, src_len]\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m     \u001b[0mattn_output_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattn_output_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# [batch_size * num_heads, tgt_len, src_len]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m     \u001b[0mattn_output_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattn_output_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdropout_p\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0mattn_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattn_output_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36msoftmax\u001b[0;34m(input, dim, _stacklevel, dtype)\u001b[0m\n\u001b[1;32m   1816\u001b[0m         \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_softmax_dim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"softmax\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_stacklevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1817\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1818\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1819\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1820\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "config = Config()\n",
    "train_model(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
